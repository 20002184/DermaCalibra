#!/usr/bin/env python3
"""
æµ‹è¯•å¹³è¡¡æµ‹è¯•é›†çš„å®é™…å‡†ç¡®ç‡
"""

import os
import sys
import torch
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
from torchvision import transforms
from sklearn.preprocessing import StandardScaler

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/yue/wbwb/VisualMetaGuidedSkinLesionClassification')

from pad_model.resnet import resnet_pad
from utils.custom_dataset import meta_img_dataset_test

def test_balanced_dataset():
    """æµ‹è¯•å¹³è¡¡æµ‹è¯•é›†"""
    print("=== æµ‹è¯•å¹³è¡¡æµ‹è¯•é›† ===")
    
    # è®¾ç½®å‚æ•°
    dataset_path = "/home/yue/wbwb/VisualMetaGuidedSkinLesionClassification/balanced_testset"
    model_path = "/home/yue/wbwb/VisualMetaGuidedSkinLesionClassification/BEST/resnet_amcr_sota.pkl"
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¯»å–æ•°æ®é›†
    csv_path = os.path.join(dataset_path, "balanced_dataset.csv")
    imgs_dir = os.path.join(dataset_path, "imgs")
    
    df = pd.read_csv(csv_path)
    print(f"å¹³è¡¡æµ‹è¯•é›†åŒ…å« {len(df)} ä¸ªæ ·æœ¬")
    
    # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
    print("\nç±»åˆ«åˆ†å¸ƒ:")
    class_counts = df['diagnostic'].value_counts()
    for diagnostic, count in class_counts.items():
        percentage = (count / len(df)) * 100
        print(f"  {diagnostic}: {count} ({percentage:.1f}%)")
    
    # è·å–å…ƒæ•°æ®åˆ—
    meta_columns = [col for col in df.columns if col not in ['img_id', 'diagnostic', 'diagnostic_number', 'patient_id', 'lesion_id', 'biopsed', 'folder']]
    print(f"å…ƒæ•°æ®ç‰¹å¾æ•°: {len(meta_columns)}")
    
    # å‡†å¤‡æ•°æ®
    meta_data = df[meta_columns].values.astype(np.float32)
    labels = df['diagnostic_number'].values
    
    # æ ‡å‡†åŒ–å…ƒæ•°æ®
    scaler = StandardScaler()
    meta_data = scaler.fit_transform(meta_data).astype(np.float32)
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # æ„å»ºå›¾åƒè·¯å¾„åˆ—è¡¨
    test_imgs_path = []
    for img_id in df['img_id']:
        img_path = os.path.join(imgs_dir, f"{img_id}.jpg")
        test_imgs_path.append(img_path)
    
    # æ£€æŸ¥å›¾åƒæ–‡ä»¶
    print("\næ£€æŸ¥å›¾åƒæ–‡ä»¶...")
    missing_count = 0
    for i, img_path in enumerate(test_imgs_path[:10]):
        if os.path.exists(img_path):
            print(f"  {i+1}: {os.path.basename(img_path)} å­˜åœ¨")
        else:
            print(f"  {i+1}: {os.path.basename(img_path)} ä¸å­˜åœ¨")
            missing_count += 1
    
    if missing_count > 0:
        print(f"  è­¦å‘Š: å‰10ä¸ªå›¾åƒä¸­æœ‰ {missing_count} ä¸ªä¸å­˜åœ¨")
    
    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    checkpoint = torch.load(model_path, map_location=device)
    model = checkpoint
    model = model.to(device)
    model.eval()
    print("æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # åˆ›å»ºæ•°æ®é›†
    test_dataset = meta_img_dataset_test(test_imgs_path, meta_data, labels, transform)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
    
    # è¿›è¡Œæ¨ç†æµ‹è¯•
    print("\nå¼€å§‹æ¨ç†æµ‹è¯•...")
    predictions = []
    true_labels = []
    correct_count = 0
    total_count = 0
    
    class_names = ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']
    
    with torch.no_grad():
        for batch_idx, (imgs_batch, metadata_batch, batch_y) in enumerate(test_loader):
            imgs_batch = imgs_batch.float().to(device)
            metadata_batch = metadata_batch.float().to(device)
            batch_y = batch_y.long().to(device)
            
            try:
                outputs = model(imgs_batch, metadata_batch)
                logits = outputs[0]  # resnet_pad outputs [x, c1, c2, c3]
                
                _, predicted = torch.max(logits, 1)
                
                # æ”¶é›†é¢„æµ‹ç»“æœ
                batch_predictions = predicted.cpu().numpy()
                batch_true_labels = batch_y.cpu().numpy()
                
                predictions.extend(batch_predictions)
                true_labels.extend(batch_true_labels)
                
                # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹æ•°
                batch_correct = (batch_predictions == batch_true_labels).sum()
                correct_count += batch_correct
                total_count += len(batch_y)
                
                if (batch_idx + 1) % 100 == 0:
                    print(f"  æ‰¹æ¬¡ {batch_idx + 1}: å¤„ç†äº† {len(batch_y)} ä¸ªæ ·æœ¬")
                
            except Exception as e:
                print(f"  æ‰¹æ¬¡ {batch_idx + 1} å¤„ç†å¤±è´¥: {e}")
                continue
    
    # è®¡ç®—å‡†ç¡®ç‡
    if len(predictions) > 0:
        predictions = np.array(predictions)
        true_labels = np.array(true_labels)
        
        accuracy = (predictions == true_labels).mean()
        print(f"\næ¨ç†æµ‹è¯•å®Œæˆ!")
        print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(predictions)}")
        print(f"å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"æ­£ç¡®é¢„æµ‹æ•°: {correct_count}")
        print(f"æ€»æ ·æœ¬æ•°: {total_count}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        unique_classes = sorted(np.unique(true_labels))
        
        print("\næŒ‰ç±»åˆ«ç»Ÿè®¡:")
        for class_idx in unique_classes:
            if class_idx < len(class_names):
                class_name = class_names[class_idx]
                class_mask = true_labels == class_idx
                if class_mask.sum() > 0:
                    class_accuracy = (predictions[class_mask] == true_labels[class_mask]).mean()
                    class_correct = (predictions[class_mask] == true_labels[class_mask]).sum()
                    print(f"  {class_name}: {class_mask.sum()} æ ·æœ¬, å‡†ç¡®ç‡ {class_accuracy:.4f}, æ­£ç¡® {class_correct}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯é¢„æµ‹
        incorrect_indices = np.where(predictions != true_labels)[0]
        if len(incorrect_indices) > 0:
            print(f"\nå‘ç° {len(incorrect_indices)} ä¸ªé”™è¯¯é¢„æµ‹:")
            for i, idx in enumerate(incorrect_indices[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                pred_class = class_names[predictions[idx]] if predictions[idx] < len(class_names) else f"æœªçŸ¥({predictions[idx]})"
                true_class = class_names[true_labels[idx]] if true_labels[idx] < len(class_names) else f"æœªçŸ¥({true_labels[idx]})"
                print(f"  æ ·æœ¬ {idx}: é¢„æµ‹ {pred_class}, çœŸå® {true_class}")
            if len(incorrect_indices) > 10:
                print(f"  ... è¿˜æœ‰ {len(incorrect_indices) - 10} ä¸ªé”™è¯¯é¢„æµ‹")
        else:
            print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰é¢„æµ‹éƒ½æ­£ç¡®ï¼100%å‡†ç¡®ç‡ï¼")
        
        # æ˜¾ç¤ºå‰10ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
        print(f"\nå‰10ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ:")
        for i in range(min(10, len(predictions))):
            pred_class = class_names[predictions[i]] if predictions[i] < len(class_names) else f"æœªçŸ¥({predictions[i]})"
            true_class = class_names[true_labels[i]] if true_labels[i] < len(class_names) else f"æœªçŸ¥({true_labels[i]})"
            is_correct = predictions[i] == true_labels[i]
            status = "âœ“" if is_correct else "âœ—"
            print(f"  æ ·æœ¬ {i+1}: {status} é¢„æµ‹ {pred_class}, çœŸå® {true_class}")
        
        # è¯„ä¼°ç»“æœ
        print(f"\n=== è¯„ä¼°ç»“æœ ===")
        if accuracy >= 0.70:
            print(f"âœ… æˆåŠŸï¼å‡†ç¡®ç‡ {accuracy*100:.2f}% è¾¾åˆ°70%ä»¥ä¸Šè¦æ±‚")
        else:
            print(f"âŒ å¤±è´¥ï¼å‡†ç¡®ç‡ {accuracy*100:.2f}% æœªè¾¾åˆ°70%è¦æ±‚")
        
        if len(predictions) >= 5000:
            print(f"âœ… æˆåŠŸï¼æ ·æœ¬æ•° {len(predictions)} è¾¾åˆ°5000ä¸ªä»¥ä¸Šè¦æ±‚")
        else:
            print(f"âŒ å¤±è´¥ï¼æ ·æœ¬æ•° {len(predictions)} æœªè¾¾åˆ°5000ä¸ªè¦æ±‚")
        
        print(f"\næœ€ç»ˆç»“æœ: {len(predictions)} ä¸ªæ ·æœ¬ï¼Œå‡†ç¡®ç‡ {accuracy*100:.2f}%")
        
        # ä¸é¢„æœŸå‡†ç¡®ç‡æ¯”è¾ƒ
        expected_accuracy = 0.80  # 80%
        print(f"\né¢„æœŸå‡†ç¡®ç‡: {expected_accuracy*100:.2f}%")
        print(f"å®é™…å‡†ç¡®ç‡: {accuracy*100:.2f}%")
        if accuracy >= expected_accuracy:
            print(f"âœ… å®é™…å‡†ç¡®ç‡è¾¾åˆ°æˆ–è¶…è¿‡é¢„æœŸï¼")
        else:
            print(f"âŒ å®é™…å‡†ç¡®ç‡ä½äºé¢„æœŸ")
    else:
        print("æ¨ç†æµ‹è¯•å¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸå¤„ç†çš„æ ·æœ¬")

if __name__ == "__main__":
    test_balanced_dataset() 